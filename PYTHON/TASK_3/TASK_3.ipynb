{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "from skimage.feature import hog\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка изображений\n",
    "def load_image(folder_path, target_size=(45, 45)):\n",
    "  imgs = []\n",
    "  lables = []\n",
    "  lable = 0\n",
    "  \n",
    "  dirs = natsorted(list(os.walk(folder_path))[0][1])\n",
    "  named_labels = dirs\n",
    "  for dir_ in dirs:\n",
    "    curr_dir = folder_path + '/' + dir_\n",
    "    os.chdir(curr_dir)\n",
    "    files = natsorted(list(os.walk(curr_dir))[0][2])\n",
    "    file_cnt = 0\n",
    "    for file in files:\n",
    "      img = cv2.imread(file)\n",
    "      img_resized = cv2.resize(img, target_size)\n",
    "\n",
    "      img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "      img_norm = img_gray / 255.0\n",
    "\n",
    "      clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "      img_enhanced = clahe.apply((img_norm * 255).astype(np.uint8))\n",
    "      \n",
    "      imgs.append(hog(img_enhanced, orientations=9, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False))\n",
    "      \n",
    "      lables.append(lable)\n",
    "      if file_cnt == 99:\n",
    "        lable += 1\n",
    "        break\n",
    "      file_cnt += 1\n",
    "\n",
    "  return imgs, lables, named_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение изображений, меток и символов? соответствующих меткам классов\n",
    "imgs, lables, named_labels = load_image(\"/home/RuDe/Space/Institute/МФТИ/Python/Dev/Semester_10/hw_3/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knn&#x27;, KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knn&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание конвейера для стандиртизации данных\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier())])\n",
    "pipe.fit(imgs, lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение тестового математического выражения для распознавания\n",
    "test_path = \"/home/RuDe/Space/Institute/МФТИ/Python/Dev/Semester_10/hw_3/test_exp\"\n",
    "files = natsorted(list(os.walk(test_path))[0][2])\n",
    "target_size = (45, 45)\n",
    "\n",
    "test_imgs = []\n",
    "\n",
    "os.chdir(test_path)\n",
    "for file in files:\n",
    "  img = cv2.imread(file)\n",
    "  img_resized = cv2.resize(img, target_size)\n",
    "\n",
    "  img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "  img_norm = img_gray / 255.0\n",
    "\n",
    "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "  img_enhanced = clahe.apply((img_norm * 255).astype(np.uint8))\n",
    "  \n",
    "  test_imgs.append(hog(img_enhanced, orientations=9, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вывода результата распознавания\n",
    "def show_res(y_pred):\n",
    "  for y in y_pred:\n",
    "    print(named_labels[y], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1-9)"
     ]
    }
   ],
   "source": [
    "# Распознавание математического выражения\n",
    "y_pred = pipe.predict(test_imgs)\n",
    "show_res(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs, lables, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weight': 'distance', 'metric': 'cosine', 'neighbor_num': 9, 'acc': 0.8095238095238095}\n"
     ]
    }
   ],
   "source": [
    "# Перебор гиперпараметров модели KNN\n",
    "best = {\"weight\": '', \"metric\": '', \"neighbor_num\": 0, \"acc\": -1}\n",
    "for weight in [\"uniform\", \"distance\"]:\n",
    "  for metric in [\"minkowski\", \"cosine\", \"euclidean\"]:\n",
    "    for neighbor_num in range(2, 60):\n",
    "      pipe = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=neighbor_num, weights=weight, metric=metric))])\n",
    "      pipe.fit(X_train, y_train)\n",
    "      acc = accuracy_score(y_test, pipe.predict(X_test))\n",
    "      if best[\"acc\"] < acc:\n",
    "        best[\"weight\"] = weight\n",
    "        best[\"metric\"] = metric\n",
    "        best[\"neighbor_num\"] = neighbor_num\n",
    "        best[\"acc\"] = acc\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=9,\n",
       "                                      weights=&#x27;distance&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=9,\n",
       "                                      weights=&#x27;distance&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=9, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(metric='cosine', n_neighbors=9,\n",
       "                                      weights='distance'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение модели KNN\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=best[\"neighbor_num\"], weights=best[\"weight\"], metric=best[\"metric\"]))])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1-9)"
     ]
    }
   ],
   "source": [
    "# Распознавание тестового математического выражения\n",
    "y_pred = pipe.predict(test_imgs)\n",
    "show_res(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения строки с распознанным математическим выражением по меткам классов\n",
    "def get_expression(y_pred):\n",
    "  ret = \"\"\n",
    "\n",
    "  for y in y_pred:\n",
    "    ret += named_labels[y]\n",
    "\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1-9)\n"
     ]
    }
   ],
   "source": [
    "# Получение строки с математическим выражением\n",
    "expr = get_expression(y_pred)\n",
    "print(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "-8\n"
     ]
    }
   ],
   "source": [
    "# Проверка корректности результата распознавания\n",
    "checked_expr = re.fullmatch(r\"\\(\\d+[-+*/^]\\d+\\)\", expr)\n",
    "if checked_expr is not None:\n",
    "  print(\"Correct!\")\n",
    "  print(eval(expr))\n",
    "else:\n",
    "  print(\"Incorrect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение тестового математического выражения\n",
    "test_path = \"/home/RuDe/Space/Institute/МФТИ/Python/Dev/Semester_10/hw_3/test_exp\"\n",
    "files = natsorted(list(os.walk(test_path))[0][2])\n",
    "target_size = (45, 45)\n",
    "\n",
    "test2_imgs = []\n",
    "\n",
    "os.chdir(test_path)\n",
    "for file in files:\n",
    "  img = cv2.imread(file)\n",
    "  img_resized = cv2.resize(img, target_size)\n",
    "\n",
    "  img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "  img_norm = img_gray / 255.0\n",
    "\n",
    "  test2_imgs.append(img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединение изображений симоволов\n",
    "concat_img = cv2.hconcat(test2_imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование изображения 0 и 1\n",
    "mask_size = (5, 5)\n",
    "res_str = \"\"\n",
    "for row in range(0, concat_img.shape[0], 5):\n",
    "  for col in range(0, concat_img.shape[0], 5):\n",
    "    average_value = sum(sum(concat_img[row:row + 5, col:col + 5])) / (mask_size[0] * mask_size[1])\n",
    "    if average_value < 1:\n",
    "      res_str += '0'\n",
    "    else:\n",
    "      res_str += '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено совпадений: 0\n"
     ]
    }
   ],
   "source": [
    "# Поиск шаблона в закодированной строке изображения\n",
    "print(\"Найдено совпадений:\", len(re.findall(r\"010\", res_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
